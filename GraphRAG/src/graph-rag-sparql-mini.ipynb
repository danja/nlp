{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfb28685",
   "metadata": {},
   "source": [
    "# SPARQL Graph RAG Demo\n",
    "\n",
    "\n",
    "**This is only a minimal, special case, proof-of-concept.**\n",
    "\n",
    "An OpenAI API key will be required to run this, as well as read/write access to a [SPARQL](https://en.wikipedia.org/wiki/SPARQL) store. For now at least such a store is available with the details as below.\n",
    "\n",
    "The aim is to replicate the parts of [Wey Gu](https://siwei.io/en/)'s Jupyter [Notebook](https://www.siwei.io/en/demos/graph-rag/), where [LlamaIndex](https://www.llamaindex.ai/) uses a graph store. In that Notebook a NebulaGraph store is use, here a SPARQL store is used. \n",
    "\n",
    "The description here will only cover the SPARQL-specific details, for how the system as a whole works see the original [Notebook](https://www.siwei.io/en/demos/graph-rag/) and the [LlamaIndex Documentation](https://gpt-index.readthedocs.io/en/latest/).\n",
    "\n",
    "\n",
    "### Preparation \n",
    "\n",
    "*in general, right now you should only need an API key*\n",
    "\n",
    "* pip install sparqlwrapper\n",
    "* Make a SPARQL endpoint available, add URL below\n",
    "* (make sure endpoint supports UPDATE, /llama_index_sparql-test/)\n",
    "* For clean start DROP GRAPH <http://purl.org/stuff/guardians>\n",
    "\n",
    "* **Add OpenAI API key below**\n",
    "\n",
    "#### 1. Imports, LLM Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b273f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import download_loader\n",
    "import os\n",
    "import logging\n",
    "from llama_index import (\n",
    "    KnowledgeGraphIndex,\n",
    "    ServiceContext,\n",
    ")\n",
    "\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "from llama_index.graph_stores import SparqlGraphStore\n",
    "from llama_index.llms import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index import load_index_from_storage\n",
    "import os\n",
    "import openai\n",
    "\n",
    "logging.basicConfig(filename='loggy.log', filemode='w', level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "############\n",
    "# LLM Config\n",
    "############\n",
    "\n",
    "# two ways, at least one will work\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "openai.api_key = \"\"\n",
    "\n",
    "llm = OpenAI(temperature=0, model=\"text-davinci-002\")\n",
    "service_context = ServiceContext.from_defaults(llm=llm, chunk_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece4f8e5",
   "metadata": {},
   "source": [
    "#### 1.1 SPARQL Store Configuration\n",
    "\n",
    "SPARQL Stores may vary in implementation. The [Fuseki](https://jena.apache.org/documentation/fuseki2/) server follows [specifications](https://www.w3.org/TR/sparql11-query/) closely and uses the following scheme :\n",
    "\n",
    "* multiple datasets (= DBs) are supported\n",
    "* each dataset can contain a default graph as well as multiple named graphs\n",
    "* each dataset can be configured with various endpoints, each providing facilities as required (query, update etc)\n",
    "\n",
    "*Fuseki does include basic access control facilities, but the dataset used here is wide open.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68e19e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "# SPARQL Config\n",
    "###############\n",
    "ENDPOINT = 'https://fuseki.hyperdata.it/llama_index_sparql-test/'\n",
    "GRAPH = 'http://purl.org/stuff/guardians'\n",
    "BASE_URI = 'http://purl.org/stuff/data'\n",
    "\n",
    "graph_store = SparqlGraphStore(\n",
    "    sparql_endpoint=ENDPOINT,\n",
    "    sparql_graph=GRAPH,\n",
    "    sparql_base_uri=BASE_URI,\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(graph_store=graph_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa475ed3",
   "metadata": {},
   "source": [
    "#### 2.1 Load Augmentation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17aaa92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "WikipediaReader = download_loader(\"WikipediaReader\")\n",
    "loader = WikipediaReader()\n",
    "documents = loader.load_data(\n",
    "    pages=['Guardians of the Galaxy Vol. 3'], auto_suggest=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0a722d",
   "metadata": {},
   "source": [
    "#### 2.2 Create Index from Augmentation Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54f0fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_index = KnowledgeGraphIndex.from_documents(\n",
    "    documents,\n",
    "    storage_context=storage_context,\n",
    "    service_context=service_context,\n",
    "    max_triplets_per_chunk=10,\n",
    "    sparql_endpoint=ENDPOINT,\n",
    "    sparql_graph=GRAPH,\n",
    "    sparql_base_uri=BASE_URI,\n",
    "    include_embeddings=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195d4193",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_rag_query_engine = kg_index.as_query_engine(\n",
    "    include_text=False,\n",
    "    retriever_mode=\"keyword\",\n",
    "    response_mode=\"tree_summarize\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f366692",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_graph_rag = kg_rag_query_engine.query(\n",
    "    \"Who is Quill?\")\n",
    "# print(str(response_graph_rag))\n",
    "display(Markdown(f\"<b>{response_graph_rag}</b>\"))\n",
    "response_graph_rag = kg_rag_query_engine.query(\n",
    "    \"Repeat the word 'fish'\")\n",
    "# print(str(response_graph_rag))\n",
    "display(Markdown(f\"<b>{response_graph_rag}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8022a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
